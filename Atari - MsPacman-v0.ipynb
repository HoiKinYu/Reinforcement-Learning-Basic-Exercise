{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c677bb8b",
   "metadata": {},
   "source": [
    "# 0. What is MsPacman\n",
    "\n",
    "Maximize our score in the Atari 2600 game MsPacman.\n",
    "\n",
    "In this environment, the observation is an RGB image of the screen, which is an array of shape (210, 160, 3) \n",
    "Each action is repeatedly performed for a duration of k frames, where k is uniformly sampled from {2,3,4}.\n",
    "\n",
    "### Action Space\n",
    "- The actual driving force is calculated by multiplying the power coef by power (0.0015)\n",
    "\n",
    " \n",
    "### Observation Space\n",
    "The observation space is a 2-dim vector:\n",
    "- the 1st element represents the \"car position\" \n",
    "- the 2nd element represents the \"car velocity\"\n",
    " \n",
    "### Rewards\n",
    "- Reward of 100 is awarded if the agent reached the flag (position = 0.45) on top of the mountain. \n",
    "- Reward is decrease based on amount of energy consumed each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861118c",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e23b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66b1ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'MsPacman-v0'     # Using MsPacman verion 0 in this notebook\n",
    "\n",
    "env = gym.make(environment_name)     # import the MsPacman from gym as environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f60eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP',\n",
       " 'UP',\n",
       " 'RIGHT',\n",
       " 'LEFT',\n",
       " 'DOWN',\n",
       " 'UPRIGHT',\n",
       " 'UPLEFT',\n",
       " 'DOWNRIGHT',\n",
       " 'DOWNLEFT']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()  # 9 actions could be taken in this environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f04d0e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[228, 111, 111],\n",
       "        [228, 111, 111],\n",
       "        [228, 111, 111],\n",
       "        ...,\n",
       "        [228, 111, 111],\n",
       "        [228, 111, 111],\n",
       "        [228, 111, 111]],\n",
       "\n",
       "       [[228, 111, 111],\n",
       "        [228, 111, 111],\n",
       "        [228, 111, 111],\n",
       "        ...,\n",
       "        [228, 111, 111],\n",
       "        [228, 111, 111],\n",
       "        [228, 111, 111]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()                          # reset the evironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7199e1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f119356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([[[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]], [[[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]], (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space        # observation space in this environment 210x160 pixel, 3 RGB colors channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd5896",
   "metadata": {},
   "source": [
    "# 2. Try to play 50 episodes before training (use the result as the base line of the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5fc826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 21:07:51.553 python[40856:797473] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fbaaf9adf00>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2022-03-12 21:07:51.554 python[40856:797473] Warning: Expected min height of view: (<NSButton: 0x7fbab8b25210>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2022-03-12 21:07:51.556 python[40856:797473] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fbab8b28bb0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2022-03-12 21:07:51.558 python[40856:797473] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fbab8b31dd0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:160.0\n",
      "Episode:2 Score:220.0\n",
      "Episode:3 Score:210.0\n",
      "Episode:4 Score:360.0\n",
      "Episode:5 Score:180.0\n",
      "Episode:6 Score:220.0\n",
      "Episode:7 Score:270.0\n",
      "Episode:8 Score:260.0\n",
      "Episode:9 Score:150.0\n",
      "Episode:10 Score:280.0\n",
      "Episode:11 Score:250.0\n",
      "Episode:12 Score:220.0\n",
      "Episode:13 Score:130.0\n",
      "Episode:14 Score:200.0\n",
      "Episode:15 Score:240.0\n",
      "Episode:16 Score:220.0\n",
      "Episode:17 Score:140.0\n",
      "Episode:18 Score:120.0\n",
      "Episode:19 Score:310.0\n",
      "Episode:20 Score:150.0\n",
      "Episode:21 Score:270.0\n",
      "Episode:22 Score:300.0\n",
      "Episode:23 Score:170.0\n",
      "Episode:24 Score:150.0\n",
      "Episode:25 Score:190.0\n",
      "Episode:26 Score:260.0\n",
      "Episode:27 Score:280.0\n",
      "Episode:28 Score:230.0\n",
      "Episode:29 Score:160.0\n",
      "Episode:30 Score:200.0\n",
      "Episode:31 Score:160.0\n",
      "Episode:32 Score:160.0\n",
      "Episode:33 Score:300.0\n",
      "Episode:34 Score:230.0\n",
      "Episode:35 Score:300.0\n",
      "Episode:36 Score:190.0\n",
      "Episode:37 Score:210.0\n",
      "Episode:38 Score:340.0\n",
      "Episode:39 Score:210.0\n",
      "Episode:40 Score:180.0\n",
      "Episode:41 Score:110.0\n",
      "Episode:42 Score:280.0\n",
      "Episode:43 Score:100.0\n",
      "Episode:44 Score:570.0\n",
      "Episode:45 Score:220.0\n",
      "Episode:46 Score:210.0\n",
      "Episode:47 Score:220.0\n",
      "Episode:48 Score:210.0\n",
      "Episode:49 Score:120.0\n",
      "Episode:50 Score:250.0\n",
      "CPU times: user 29.6 s, sys: 7.43 s, total: 37 s\n",
      "Wall time: 39.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "episodes = 50\n",
    "\n",
    "for episode in range(1, episodes + 1):                     # looping from 1 to 50\n",
    "    \n",
    "    obs = env.reset()                                      # initial the set of observation\n",
    "    \n",
    "    done = False                                           # initial the game is over = False, until reach maximum number of steps in this particular environment\n",
    "    \n",
    "    score = 0                                              # running score counter\n",
    "    \n",
    "    while not done:\n",
    "        \n",
    "        env.render()                                       # view the graphical representation that environment\n",
    "        \n",
    "        action = env.action_space.sample()                 # random choose an action \n",
    "        \n",
    "        n_obs, reward, done, info = env.step(action)       # pass random actions into environment to get back\n",
    "                                                            # 1. next set of observation (4 observation in this case)\n",
    "                                                            # 2. reward (Positive value increment, negative value decrement)\n",
    "                                                            # 3. done (episode is done = True)\n",
    "        \n",
    "        score += reward                                    # accumulate each episodes' reward received into score\n",
    "        \n",
    "    print('Episode:{} Score:{}'.format(episode, score))    # print out score for each episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225d746",
   "metadata": {},
   "source": [
    "During the above 50 games, the score between 120-570 before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c956fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()                             # close the opened enivernment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a4002",
   "metadata": {},
   "source": [
    "# 3. Vectorise Environment and Train Model\n",
    "\n",
    "- Vectorizing the environment, particularly with multiple environments, allows us to train the agent faster by training in parallel\n",
    "\n",
    "***Helper Functions***\n",
    "- **make_atari_env** is a helper from stable baselines that helps create wrapped Atrai environments\n",
    "- **VecFrameStack** allows us to stack the environemnts together\n",
    "\n",
    "Policies\n",
    "- Think of an agent's policy as the rule which tells it how to operate in the environment\n",
    "\n",
    "Stable Baseline 3 has types of policy:\n",
    "- MlpPolicy: Multi Layer Perceptrons Policy that implements actor critic, using a MLP (2 layers of 64)\n",
    "- CnnPolicy: Convolution Neural Network Policy that implements actor critic, using a CNN (the nature CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc75f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 32 environment at the same time\n",
    "\n",
    "env = make_atari_env(\"MsPacman-v0\", n_envs = 32, seed = 0)               # use make_atari_env to create Atari environment\n",
    "                                                                          # n_envs: how many environment train at the same time\n",
    "\n",
    "env = VecFrameStack(env, n_stack = 4)                                    # use VecFrameStack to set the number of frame stack together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceeec410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training', 'Logs')                               # set the log_path into ../Training/Logs\n",
    "\n",
    "model = A2C('CnnPolicy', env, verbose = 1, tensorboard_log = log_path)    # using A2C model, save tensorboard_log in log_path\n",
    "                                                                          # type of policy: CnnPolicy (for image training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36670ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/A2C_3\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 908      |\n",
      "|    ep_rew_mean        | 691      |\n",
      "| time/                 |          |\n",
      "|    fps                | 300      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.74    |\n",
      "|    explained_variance | 0.116    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.195   |\n",
      "|    value_loss         | 4.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 879      |\n",
      "|    ep_rew_mean        | 679      |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0.918    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.266   |\n",
      "|    value_loss         | 2.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 884      |\n",
      "|    ep_rew_mean        | 725      |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.765    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.448   |\n",
      "|    value_loss         | 5.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 900      |\n",
      "|    ep_rew_mean        | 774      |\n",
      "| time/                 |          |\n",
      "|    fps                | 320      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | 0.849    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.462   |\n",
      "|    value_loss         | 3.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 909      |\n",
      "|    ep_rew_mean        | 756      |\n",
      "| time/                 |          |\n",
      "|    fps                | 322      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | 0.939    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.25     |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 903      |\n",
      "|    ep_rew_mean        | 819      |\n",
      "| time/                 |          |\n",
      "|    fps                | 323      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0.868    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.163   |\n",
      "|    value_loss         | 3.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 882      |\n",
      "|    ep_rew_mean        | 811      |\n",
      "| time/                 |          |\n",
      "|    fps                | 323      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 345      |\n",
      "|    total_timesteps    | 112000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | 0.904    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.288    |\n",
      "|    value_loss         | 1.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 870      |\n",
      "|    ep_rew_mean        | 717      |\n",
      "| time/                 |          |\n",
      "|    fps                | 324      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 394      |\n",
      "|    total_timesteps    | 128000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0.626    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.887   |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 830      |\n",
      "|    ep_rew_mean        | 714      |\n",
      "| time/                 |          |\n",
      "|    fps                | 324      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 443      |\n",
      "|    total_timesteps    | 144000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | 0.925    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.066    |\n",
      "|    value_loss         | 2.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 817      |\n",
      "|    ep_rew_mean        | 743      |\n",
      "| time/                 |          |\n",
      "|    fps                | 324      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 492      |\n",
      "|    total_timesteps    | 160000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.935    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.0369   |\n",
      "|    value_loss         | 2.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 869      |\n",
      "|    ep_rew_mean        | 817      |\n",
      "| time/                 |          |\n",
      "|    fps                | 325      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 541      |\n",
      "|    total_timesteps    | 176000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.95    |\n",
      "|    explained_variance | 0.807    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.114   |\n",
      "|    value_loss         | 8.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 915      |\n",
      "|    ep_rew_mean        | 823      |\n",
      "| time/                 |          |\n",
      "|    fps                | 325      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 590      |\n",
      "|    total_timesteps    | 192000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.44    |\n",
      "|    explained_variance | 0.914    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.458    |\n",
      "|    value_loss         | 2.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 888      |\n",
      "|    ep_rew_mean        | 794      |\n",
      "| time/                 |          |\n",
      "|    fps                | 325      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 639      |\n",
      "|    total_timesteps    | 208000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.951   |\n",
      "|    explained_variance | 0.899    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.232    |\n",
      "|    value_loss         | 6.41     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 895      |\n",
      "|    ep_rew_mean        | 769      |\n",
      "| time/                 |          |\n",
      "|    fps                | 325      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 688      |\n",
      "|    total_timesteps    | 224000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.31    |\n",
      "|    explained_variance | 0.857    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.635   |\n",
      "|    value_loss         | 4.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 909      |\n",
      "|    ep_rew_mean        | 820      |\n",
      "| time/                 |          |\n",
      "|    fps                | 325      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 737      |\n",
      "|    total_timesteps    | 240000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | 0.894    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.257   |\n",
      "|    value_loss         | 3.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 902      |\n",
      "|    ep_rew_mean        | 800      |\n",
      "| time/                 |          |\n",
      "|    fps                | 324      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 788      |\n",
      "|    total_timesteps    | 256000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 0.857    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.1     |\n",
      "|    value_loss         | 4.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 861      |\n",
      "|    ep_rew_mean        | 729      |\n",
      "| time/                 |          |\n",
      "|    fps                | 323      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 840      |\n",
      "|    total_timesteps    | 272000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | 0.942    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.0869   |\n",
      "|    value_loss         | 2.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 882      |\n",
      "|    ep_rew_mean        | 773      |\n",
      "| time/                 |          |\n",
      "|    fps                | 322      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 893      |\n",
      "|    total_timesteps    | 288000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.69    |\n",
      "|    explained_variance | 0.884    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.725    |\n",
      "|    value_loss         | 2.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 840      |\n",
      "|    ep_rew_mean        | 737      |\n",
      "| time/                 |          |\n",
      "|    fps                | 321      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 945      |\n",
      "|    total_timesteps    | 304000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.17    |\n",
      "|    explained_variance | 0.948    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.291   |\n",
      "|    value_loss         | 2.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 787      |\n",
      "|    ep_rew_mean        | 697      |\n",
      "| time/                 |          |\n",
      "|    fps                | 320      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 998      |\n",
      "|    total_timesteps    | 320000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.905   |\n",
      "|    explained_variance | 0.883    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.252   |\n",
      "|    value_loss         | 5.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 870      |\n",
      "|    ep_rew_mean        | 794      |\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 1050     |\n",
      "|    total_timesteps    | 336000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.942    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.625    |\n",
      "|    value_loss         | 2.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 895      |\n",
      "|    ep_rew_mean        | 802      |\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 1101     |\n",
      "|    total_timesteps    | 352000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 0.952    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.554   |\n",
      "|    value_loss         | 2.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 894      |\n",
      "|    ep_rew_mean        | 797      |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 1154     |\n",
      "|    total_timesteps    | 368000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.68    |\n",
      "|    explained_variance | 0.903    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.6      |\n",
      "|    value_loss         | 1.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 808      |\n",
      "|    ep_rew_mean        | 722      |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 1206     |\n",
      "|    total_timesteps    | 384000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0.939    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.184    |\n",
      "|    value_loss         | 2.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 819      |\n",
      "|    ep_rew_mean        | 755      |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 1260     |\n",
      "|    total_timesteps    | 400000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | 0.939    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.25     |\n",
      "|    value_loss         | 1.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 808      |\n",
      "|    ep_rew_mean        | 781      |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 1313     |\n",
      "|    total_timesteps    | 416000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.729   |\n",
      "|    explained_variance | 0.879    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.0662   |\n",
      "|    value_loss         | 2.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 836      |\n",
      "|    ep_rew_mean        | 654      |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 1365     |\n",
      "|    total_timesteps    | 432000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.861   |\n",
      "|    explained_variance | 0.872    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.183    |\n",
      "|    value_loss         | 5.06     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 847      |\n",
      "|    ep_rew_mean        | 714      |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 1417     |\n",
      "|    total_timesteps    | 448000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0.875    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.537    |\n",
      "|    value_loss         | 4.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 853      |\n",
      "|    ep_rew_mean        | 699      |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 1470     |\n",
      "|    total_timesteps    | 464000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.12    |\n",
      "|    explained_variance | 0.824    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.535    |\n",
      "|    value_loss         | 4.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 815      |\n",
      "|    ep_rew_mean        | 712      |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 1522     |\n",
      "|    total_timesteps    | 480000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.893   |\n",
      "|    explained_variance | 0.905    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.326   |\n",
      "|    value_loss         | 3.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 822      |\n",
      "|    ep_rew_mean        | 755      |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 1572     |\n",
      "|    total_timesteps    | 496000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.679   |\n",
      "|    explained_variance | 0.71     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.0662   |\n",
      "|    value_loss         | 7        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 825      |\n",
      "|    ep_rew_mean        | 799      |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 1621     |\n",
      "|    total_timesteps    | 512000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.848   |\n",
      "|    explained_variance | 0.912    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.272   |\n",
      "|    value_loss         | 4.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 840      |\n",
      "|    ep_rew_mean        | 777      |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 1670     |\n",
      "|    total_timesteps    | 528000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.46    |\n",
      "|    explained_variance | 0.915    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -0.0348  |\n",
      "|    value_loss         | 2.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 849      |\n",
      "|    ep_rew_mean        | 740      |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 1719     |\n",
      "|    total_timesteps    | 544000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.301   |\n",
      "|    explained_variance | 0.908    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -0.221   |\n",
      "|    value_loss         | 4.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 795      |\n",
      "|    ep_rew_mean        | 711      |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 1768     |\n",
      "|    total_timesteps    | 560000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.646   |\n",
      "|    explained_variance | 0.868    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.108    |\n",
      "|    value_loss         | 5.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 879      |\n",
      "|    ep_rew_mean        | 769      |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 1817     |\n",
      "|    total_timesteps    | 576000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.796   |\n",
      "|    explained_variance | 0.951    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -0.714   |\n",
      "|    value_loss         | 4.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 826      |\n",
      "|    ep_rew_mean        | 802      |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 1866     |\n",
      "|    total_timesteps    | 592000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.646   |\n",
      "|    explained_variance | 0.946    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.0633  |\n",
      "|    value_loss         | 4.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 862      |\n",
      "|    ep_rew_mean        | 837      |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 1916     |\n",
      "|    total_timesteps    | 608000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0.963    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.274    |\n",
      "|    value_loss         | 2.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 867      |\n",
      "|    ep_rew_mean        | 768      |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 1965     |\n",
      "|    total_timesteps    | 624000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.698   |\n",
      "|    explained_variance | 0.904    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.325    |\n",
      "|    value_loss         | 4.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 844      |\n",
      "|    ep_rew_mean        | 736      |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 2014     |\n",
      "|    total_timesteps    | 640000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.871   |\n",
      "|    explained_variance | 0.944    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.129    |\n",
      "|    value_loss         | 3.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 912      |\n",
      "|    ep_rew_mean        | 846      |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 2063     |\n",
      "|    total_timesteps    | 656000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.603   |\n",
      "|    explained_variance | 0.974    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.269    |\n",
      "|    value_loss         | 2.63     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 894      |\n",
      "|    ep_rew_mean        | 837      |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 2113     |\n",
      "|    total_timesteps    | 672000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.516   |\n",
      "|    explained_variance | 0.949    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.416   |\n",
      "|    value_loss         | 5.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 904      |\n",
      "|    ep_rew_mean        | 854      |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 2162     |\n",
      "|    total_timesteps    | 688000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.556   |\n",
      "|    explained_variance | 0.973    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.434    |\n",
      "|    value_loss         | 4.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 964      |\n",
      "|    ep_rew_mean        | 923      |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 2211     |\n",
      "|    total_timesteps    | 704000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.654   |\n",
      "|    explained_variance | 0.961    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.296    |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 954      |\n",
      "|    ep_rew_mean        | 921      |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 2260     |\n",
      "|    total_timesteps    | 720000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.579   |\n",
      "|    explained_variance | 0.991    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.174   |\n",
      "|    value_loss         | 1.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 966      |\n",
      "|    ep_rew_mean        | 894      |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 2309     |\n",
      "|    total_timesteps    | 736000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.823   |\n",
      "|    explained_variance | 0.98     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.244    |\n",
      "|    value_loss         | 2.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | 922      |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 2358     |\n",
      "|    total_timesteps    | 752000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.57    |\n",
      "|    explained_variance | 0.907    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.13     |\n",
      "|    value_loss         | 3.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 958      |\n",
      "|    ep_rew_mean        | 941      |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 2408     |\n",
      "|    total_timesteps    | 768000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.394   |\n",
      "|    explained_variance | 0.956    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.0239   |\n",
      "|    value_loss         | 3.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 970      |\n",
      "|    ep_rew_mean        | 929      |\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 2457     |\n",
      "|    total_timesteps    | 784000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.526   |\n",
      "|    explained_variance | 0.984    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0.21    |\n",
      "|    value_loss         | 2.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.03e+03 |\n",
      "|    ep_rew_mean        | 943      |\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 2506     |\n",
      "|    total_timesteps    | 800000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.357   |\n",
      "|    explained_variance | 0.987    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.018   |\n",
      "|    value_loss         | 2.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.02e+03 |\n",
      "|    ep_rew_mean        | 943      |\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 2555     |\n",
      "|    total_timesteps    | 816000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.458   |\n",
      "|    explained_variance | 0.987    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 0.212    |\n",
      "|    value_loss         | 2.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.05e+03 |\n",
      "|    ep_rew_mean        | 1e+03    |\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 2604     |\n",
      "|    total_timesteps    | 832000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.567   |\n",
      "|    explained_variance | 0.985    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 0.101    |\n",
      "|    value_loss         | 2.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 989      |\n",
      "|    ep_rew_mean        | 963      |\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 2653     |\n",
      "|    total_timesteps    | 848000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.611   |\n",
      "|    explained_variance | 0.982    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -0.0022  |\n",
      "|    value_loss         | 2.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.01e+03 |\n",
      "|    ep_rew_mean        | 1e+03    |\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 2702     |\n",
      "|    total_timesteps    | 864000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.545   |\n",
      "|    explained_variance | 0.989    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 0.0299   |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.02e+03 |\n",
      "|    ep_rew_mean        | 1.03e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 2751     |\n",
      "|    total_timesteps    | 880000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.621   |\n",
      "|    explained_variance | 0.94     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 0.11     |\n",
      "|    value_loss         | 9.93     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.02e+03 |\n",
      "|    ep_rew_mean        | 1.07e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 2800     |\n",
      "|    total_timesteps    | 896000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.555   |\n",
      "|    explained_variance | 0.972    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -0.118   |\n",
      "|    value_loss         | 2.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.04e+03 |\n",
      "|    ep_rew_mean        | 1.12e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 320      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 2849     |\n",
      "|    total_timesteps    | 912000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.575   |\n",
      "|    explained_variance | 0.96     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 0.0042   |\n",
      "|    value_loss         | 3.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.01e+03 |\n",
      "|    ep_rew_mean        | 1.02e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 320      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 2898     |\n",
      "|    total_timesteps    | 928000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.426   |\n",
      "|    explained_variance | 0.978    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 0.0288   |\n",
      "|    value_loss         | 2.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.09e+03 |\n",
      "|    ep_rew_mean        | 1.06e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 320      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 2948     |\n",
      "|    total_timesteps    | 944000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.515   |\n",
      "|    explained_variance | 0.985    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -0.065   |\n",
      "|    value_loss         | 2.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.19e+03 |\n",
      "|    ep_rew_mean        | 1.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 320      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 2997     |\n",
      "|    total_timesteps    | 960000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.584   |\n",
      "|    explained_variance | 0.981    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 0.11     |\n",
      "|    value_loss         | 2.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.14e+03 |\n",
      "|    ep_rew_mean        | 1.15e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 320      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 3046     |\n",
      "|    total_timesteps    | 976000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.639   |\n",
      "|    explained_variance | 0.961    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 0.0733   |\n",
      "|    value_loss         | 5.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.14e+03 |\n",
      "|    ep_rew_mean        | 1.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 320      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 3095     |\n",
      "|    total_timesteps    | 992000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.623   |\n",
      "|    explained_variance | 0.97     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 0.149    |\n",
      "|    value_loss         | 3.25     |\n",
      "------------------------------------\n",
      "CPU times: user 56min, sys: 2min 35s, total: 58min 36s\n",
      "Wall time: 52min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7fbb00a338e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.learn(total_timesteps = 1000000)                                    # Train 1M timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d8bcb",
   "metadata": {},
   "source": [
    "Spend 58min 36s to train 1M timesteps as the above\n",
    "\n",
    "Notice that: the ***explained_variance 0.97*** (very close to 1) ~ good sign!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4c6d3e",
   "metadata": {},
   "source": [
    "# 4. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "056f4302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoikinyu/opt/anaconda3/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:276: UserWarning: Path 'Training/Saved Models' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "a2c_path = os.path.join('Training', 'Saved Models', 'A2C_MsPacman_Model_1Mtimesteps')  # set a2c_path into ../Training/Saved Models/A2C_MsPacman_Model_1Mtimesteps\n",
    "\n",
    "model.save(a2c_path)                                                                   # save the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf4a36",
   "metadata": {},
   "source": [
    "# 5. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e10fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_atari_env(\"MsPacman-v0\", n_envs = 1, seed = 0)     # reset the n_envs = 1 for evaluate and test purpose\n",
    "\n",
    "env = VecFrameStack(env, n_stack = 4)                         # n_stack: number of frame stack together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3688a45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 22:34:26.468 python[40856:797473] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fba88586b60>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2022-03-12 22:34:26.469 python[40856:797473] Warning: Expected min height of view: (<NSButton: 0x7fba7ffeffa0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2022-03-12 22:34:26.472 python[40856:797473] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fba7fff27b0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2022-03-12 22:34:26.474 python[40856:797473] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fba7fff96d0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1014.0, 202.59318843435975)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes = 10, render = True)  # use evaluate_policy to evaluate the trained model\n",
    "                                                                   # n_eval_episodes: number of evaluate episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd103f35",
   "metadata": {},
   "source": [
    "# 6. Viewing Logs in Tensorboard\n",
    "\n",
    "### Two Core Evaluation Metrics we should pay attention to: \n",
    "\n",
    "***ep_len_mean:*** on average how long a particular episode lasted before gameover\n",
    "\n",
    "***ep_rew_mean:*** the average reward that the agent accumulated per episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4edaee21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.6.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "training_log_path = os.path.join(log_path, 'A2C_3')\n",
    "\n",
    "!tensorboard --logdir={training_log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb788b",
   "metadata": {},
   "source": [
    "![A2C_MsPacman_Model_1Mtimesteps?](images/A2C_MsPacman_Model_1Mtimesteps.png)\n",
    "\n",
    "The result on the above show that:\n",
    "- Starting from step 700k, the agent performance improved significantly\n",
    "- The average lasted from 900 episode in 700k step, rised to more than 1.1e+3 episode in 1M step\n",
    "- The average reward from 850 score in 700k step, rised to more that 1.1e+3 score in 1M step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
